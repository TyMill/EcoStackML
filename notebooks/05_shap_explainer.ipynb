# ğŸ” Notebook 05: SHAP Explainer for EcoStackML

This notebook demonstrates how to interpret models using SHAP for both base models and the meta-model.

---

## âœ… SHAP for base models

```python
stacker.explain_base_models(X_test)
```

This will produce SHAP summary plots for each base model individually.

---

## âœ… SHAP for meta-model

```python
stacker.explain_meta_model(X_test)
```

This will show the SHAP summary plot based on meta-features (i.e., predictions from base models).  
Great for understanding how the stacker makes final decisions.

---

## ğŸ§  Example output

- SHAP summary: importance and impact of each feature
- SHAP waterfall: individual prediction explanation
- SHAP bar plot (optional)

---

## ğŸ“ Summary

With just two commands, youâ€™ve:
- Visualized what base models focus on
- Explained how the meta-model makes decisions
- Made your pipeline more transparent!
