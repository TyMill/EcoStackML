# 🔍 Notebook 05: SHAP Explainer for EcoStackML

This notebook demonstrates how to interpret models using SHAP for both base models and the meta-model.

---

## ✅ SHAP for base models

```python
stacker.explain_base_models(X_test)
```

This will produce SHAP summary plots for each base model individually.

---

## ✅ SHAP for meta-model

```python
stacker.explain_meta_model(X_test)
```

This will show the SHAP summary plot based on meta-features (i.e., predictions from base models).  
Great for understanding how the stacker makes final decisions.

---

## 🧠 Example output

- SHAP summary: importance and impact of each feature
- SHAP waterfall: individual prediction explanation
- SHAP bar plot (optional)

---

## 📝 Summary

With just two commands, you’ve:
- Visualized what base models focus on
- Explained how the meta-model makes decisions
- Made your pipeline more transparent!
