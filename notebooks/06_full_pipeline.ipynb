# 🔄 Notebook 06: Full EcoStackML Pipeline

End-to-end pipeline using EcoStackML:
- Load data
- Preprocess
- Split
- Train stacking model
- Evaluate
- Explain with SHAP
- Save results

---

## 📥 1. Load data

```python
from ecostackml.data.loader import DataLoader

df = DataLoader.from_csv("notebooks/demo_data/sample.csv")
df["target"] = [0, 0, 1, 0, 1]  # synthetic target for classification
df
```

---

## 🧼 2. Clean and preprocess

```python
from ecostackml.preprocessing.cleaner import Cleaner

cleaner = Cleaner(strategy="median", scaling="standard", anomaly_method="iqr")
df_clean = cleaner.fit_transform(df)
```

---

## ✂️ 3. Split data

```python
from ecostackml.data.splitter import split_data

X_train, X_test, _, y_train, y_test, _ = split_data(df_clean, target_column="target", stratify=True)
```

---

## 🧠 4. Train stacked model

```python
from ecostackml.models.stacker import ModelStacker

stacker = ModelStacker(
    base_models_config=[
        {"name": "random_forest"},
        {"name": "xgboost"}
    ],
    meta_model_name="logistic",
    model_type="classification"
)

stacker.fit(X_train, y_train)
```

---

## 📊 5. Evaluate

```python
y_pred = stacker.predict(X_test)

import pandas as pd
meta_input = pd.DataFrame([
    model.model.predict(X_test) for model in stacker.base_models
]).T

y_proba = stacker.meta_model.model.predict_proba(meta_input)[:, 1]

from ecostackml.models.evaluator import evaluate_classification

metrics = evaluate_classification(y_test, y_pred, y_proba)
metrics
```

---

## 🔍 6. Explain with SHAP

```python
stacker.explain_base_models(X_test)
stacker.explain_meta_model(X_test)
```

---

## 💾 7. Save results

```python
from ecostackml.utils.save_load import save_model, save_metrics, save_predictions

save_model(stacker.meta_model.model, "models/stacked_meta_model.pkl")
save_predictions(y_test, y_pred, "results/predictions.csv")
save_metrics(metrics, "results/metrics.json")
```

---

## ✅ Done!

You've built a full machine learning stack, evaluated it, explained it, and saved it.
