# ğŸ“Š Notebook 04: Model Evaluation with EcoStackML

This notebook demonstrates how to evaluate a trained model using metrics and visualizations.

---

## ğŸ“¦ Predict with a trained stacker

```python
# If not already defined:
# from ecostackml.models.stacker import ModelStacker
# stacker.fit(X_train, y_train)

y_pred = stacker.predict(X_test)

# Meta-model input
import pandas as pd
meta_input = pd.DataFrame([
    model.model.predict(X_test) for model in stacker.base_models
]).T

y_proba = stacker.meta_model.model.predict_proba(meta_input)[:, 1]
```

---

## ğŸ“ˆ Evaluate predictions

```python
from ecostackml.models.evaluator import evaluate_classification

metrics = evaluate_classification(
    y_true=y_test,
    y_pred=y_pred,
    y_proba=y_proba,
    plot=True
)

print(metrics)
```

---

## ğŸ“ Summary

Youâ€™ve evaluated your stacked model using:
- Accuracy, F1-score, Precision, Recall
- ROC Curve + AUC
- Precision-Recall Curve
- Confusion Matrix
